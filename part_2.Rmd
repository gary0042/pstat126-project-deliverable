---
title: "Project Step 2"
author: "Alec Wang, Gary Han"
date: "2023-11-04"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
# knit options
knitr::opts_chunk$set(echo = F,
                      results = 'markup',
                      fig.width = 4,
                      fig.height = 3,
                      fig.align = 'center',
                      message = F,
                      warning = F)

# packages
library(knitr)
library(tidyverse)
library(faraway)
library(ggplot2)
library(skimr)
library(readxl)
```

## Recap
```{r, results='hide', echo=FALSE}
df <- read.table("adult.data")
df[df == "?,"] <- NA
adult <- na.omit(df)
colnames(adult) <- c("age", "workclass", "fnlwgt", "education", "education-num", "marital-status", "occupation", "relationship", "race", "sex", "capital-gain", "capital-loss", "hours-per-week", "native-country", "income")
mutate(.data = adult, "age" = as.numeric("age"))
set.seed(12345)
adult <- adult[sample(nrow(adult), 500), ]
adult[] <- lapply(adult, function(x) gsub(",", "", x))
integer_cols <- c("age", "fnlwgt", "education-num", "capital-gain", "capital-loss", "hours-per-week")
for (i in 1:length(integer_cols)){
  adult[, integer_cols[i]] <- as.numeric(adult[, integer_cols[i]])
}
skim(adult)
summary(adult)
```

This dataset includes 14 parameters from 30162 adults collected during the 1994 census as predictors for whether or not income exceeds $50k/yr. We have sampled 500 entries from the dataset for analysis. Note that we have used the same seed for the sample in this step so results are consistent.   
Below is a table detailing the 14 parameters and the response, that were collected in the census. The link to the source is [here](https://archive.ics.uci.edu/dataset/2/adult)

| Field           | Description                               |
|-----------------|---------------------------------------------------------|
| age             | Age in years of individual (Integer)                      |
| workclass       | Class of work of individual (7 categories)               |
| fnlwgt          | Number of people the entry represents (Integer)          |
| education       | Highest level of education of individual (16 categories) |
| education-num   | Maps each category in education to a number (Integer)    |
| marital-status  | Marital status of individual (7 categories)              |
| occupation      | Description of occupation (14 categories)                |
| relationship    | Relationship of individual relative to others (6 categories) |
| race            | Category of race of individual (5 categories)           |
| sex             | Biological sex of individual (2 categories)              |
| capital-gain    | Capital gain of individual (Integer)                     |
| capital-loss    | Capital loss of individual (Integer)                     |
| hours-per-week  | Hours worked per week by individual (Integer)           |
| income           | Whether or not income is above $50k/yr (2 categories)   |


First few lines of the dataset read:
```{r, results = 'asis', echo = F}
kable(head(adult, 8))
```
## Hypothesis
The hypothesis that we will be testing is:
$$
 H_0: \text{Hours per week worked is not linearly related to education level,}\;\; \beta_1 = 0 \\
 H_a: \text{Hours per week worked is linearly related to education level,}\;\; \beta_1 \neq 0
$$

## Linear regression assumptions
Before we proceed, we would like to check these assumptions:  

- The variance between observations is constant (homoscedasticity)  
- The model is correctly specified (linearity): ($E[Y] = \beta_0 + \beta_1x$)  

To do so, we construct a scatter plot of the variables:
```{r, fig.cap="Scatter plot of our variables of interest"}
ggplot(data = adult, aes(x = `education-num`, y = `hours-per-week`)) + geom_point(alpha = 0.2) + labs(x="Education level", y="Hours per week worked", title = "Hours worked per week vs Education level")
```
From inspection we see that the there does seem to be a slight positive correlation between our predictor and response variable. The variance does not seem to be constant. An example of this is that the spread of the response variable for $x = 15$ is wider than the spread for $x=6$. However, as prof. Mouti said, this is to be expected for real life data, so we are just going to move forward and fit a linear model to the data anyways.   

## Fitting
```{r, results = 'markup'}
model <- lm(`hours-per-week` ~ `education-num`, data = adult)
summary(model)
```
```{r, fig.cap = "Data plotted with the line of best fit (blue)"}
ggplot(data = adult, aes(x = `education-num`, y = `hours-per-week`)) + geom_point(alpha = 0.2) + labs(x="Education level", y="Hours per week worked", title="Hours worked per week vs Education level")+geom_smooth(method = 'lm', formula = y ~ x, se=FALSE)
```
## Hypothesis test
From the fit, our linear model is:
$$
E\left[y\right] = \beta_0 + \beta_1x \\
\beta_0 = 32.4013, \quad \beta_1 = 0.8376
$$
Recall that our hypothesis test is:
$$
H_0: \beta_1 = 0 \\
H_a: \beta_1 \neq 0
$$
This is a global significance test (since we only have one parameter). Reading off the F-statistic portion of the printout, we get a p-value of $2.088\times 10^{-5}$. Thus at a level of $\alpha = 0.05$, the data suggests that there is indeed a linear relationship between education level and hours per week worked. 

### Confidence interval on $\beta_1$:
```{r, echo = F, results = 'hide'}
interval <- confint(model, level = 0.95)
print(interval)
```
Using the function `confint` on our model, we can read of the 95 percent confidence interval for $\beta_1$:
$$
\beta_1 \in \left( 0.455, 1.221\right)
$$
Thus we are 95% confidence the true slope, $\beta_1$ lies in the interval $(0.455, 1.221)$, under the assumption that the observations are normally distributed about the line of best fit. Note that $\beta_1 = 0$ is not in this interval which is what we expect from the theorem about test-interval duality. 

## Residual plot
```{r, fig.cap = "Plot of the residuals. The y=0 was plotted in red for reference."}
adult$`hours-per-week-resids` <- model$residuals
ggplot(data = adult ,aes(x = `education-num`, y = `hours-per-week-resids`)) + geom_point(alpha = 0.2) + labs(x="Education level", y="Residuals") + geom_hline(yintercept = 0, col = 'red')
```
The data seems to be randomly clustered about the line $x=0$, and there does not seem to be any clear patterns in the residuals. Thus a linear model would be appropriate for this data. From before, our $R^2$ value is $0.03574$ which tells us that this regression model explains about 3.574% of the variance seen in the original data. This makes sense because looking back at our residual plot, the spread looks approximately the same (both in shape and magnitude) as the original scatter plot (so $SS_{res} \approx SS_T$ which gives a small $R^2$). 

## Individual Response
An interesting value to examine is the mean response of the number of hours worked for a bachelor's degree (education number of 13) since we are about to graduate soon. 
```{r, results = 'hide'}
new_df = data.frame(13)
colnames(new_df) <- 'education-num'
predict(model, newdata = new_df, interval ='confidence', level = 0.95)
predict(model, newdata = new_df, interval ='prediction', level = 0.95)
```
Using the `predict` function, the 95% confidence interval for the mean number of hours worked for an individual with a bachelor's is $(41.81, 44.77)$, and the 95% prediction interval for the number of hours worked for an individual with a bachelors is $(20.89, 65.70)$. The prediction interval is bigger than the confidence interval since the confidence interval makes a statement regrading the mean while the prediction interval makes a statement regarding an individual, which means it has to take into account the random errors $\varepsilon_i$. 

## Conclusion
We found that the mean number of hours worked per week, $E[y]$, can be modeled by the education level, $x$, with the following model:
$$
E\left[y\right] = \beta_0 + \beta_1x \\
\beta_0 = 32.4013, \quad \beta_1 = 0.8376
$$
Where the 95% confidence interval on $\beta_1$ was found to be $\beta_1 \in (0.455, 1.221)$. One thing that was interesting was we actually got that $\beta_1 \neq 0$ in our global significance test, as we did not think that the slight positive correlation observed in the data was significant enough to be characterized by a linear model. The results also surprised us because we thought that a lower education level correlates with more hours worked which is in direct conflict with what we found. Given the time, we would like to repeat this process with a bigger/different sample and see if we get the same results. 

























